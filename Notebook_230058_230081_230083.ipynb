{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c46dff11",
      "metadata": {},
      "source": [
        "Deployment is on : https://github.com/hdans/DataNiaga"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41f4f18",
      "metadata": {},
      "source": [
        "# Import Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bd46ac",
      "metadata": {
        "id": "46bd46ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "plt.style.use('seaborn-v0_8')\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdec1ea6",
      "metadata": {},
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f233b37e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f233b37e",
        "outputId": "a394376d-c3bc-4d4f-d855-1789d8153ad8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"data_retail2.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b961ef8",
      "metadata": {},
      "source": [
        "# Data Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f35e400",
      "metadata": {},
      "source": [
        "## Change Invoice Date to DateTime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a7b627",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "start_date = pd.to_datetime(\"2022-01-02\")\n",
        "target_date = pd.to_datetime(\"2025-12-14\")\n",
        "\n",
        "time_delta = target_date - start_date\n",
        "df['InvoiceDate'] = df['InvoiceDate'] + time_delta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7655dc5",
      "metadata": {},
      "source": [
        "## Dataset Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5ee6b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e5ee6b2",
        "outputId": "0d42a1e3-dac3-4620-c0e9-606da1476ff0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee323a75",
      "metadata": {},
      "source": [
        "## Dataset Describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270b46f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "270b46f1",
        "outputId": "5d61f907-36f9-4151-d52a-c63e580faf98"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e364e59",
      "metadata": {},
      "source": [
        "## Dataset Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d40226",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "50d40226",
        "outputId": "a72a8180-2c88-4e2a-d344-2657afda8c42"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98057c7",
      "metadata": {},
      "source": [
        "## Dataset Unique Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5253b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5253b9",
        "outputId": "3d757ead-5520-467d-893a-090c00ac6e70"
      },
      "outputs": [],
      "source": [
        "df['InvoiceNo'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31d6c64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f31d6c64",
        "outputId": "87fa45a2-ad2d-46b3-9696-ee7c0195da54"
      },
      "outputs": [],
      "source": [
        "obj_col = df.select_dtypes(include='object').columns\n",
        "for col in obj_col:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c096f9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c096f9b",
        "outputId": "0aaba6a2-839b-4b42-b737-b976ec9035b3"
      },
      "outputs": [],
      "source": [
        "df['BRANCH_SPLR'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3971961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3971961",
        "outputId": "cc1be146-3d7c-43ed-dfc9-ae2a01210549"
      },
      "outputs": [],
      "source": [
        "df['BRANCH_SPLR'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4ee0c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4ee0c4",
        "outputId": "e80beccb-3e7a-4b79-a369-2cfaaaeab3d8"
      },
      "outputs": [],
      "source": [
        "df['warehouseProductsID'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def58dea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "def58dea",
        "outputId": "1d06efb3-d864-43b4-81d6-e6fec93bf050"
      },
      "outputs": [],
      "source": [
        "df['warehouseProductsID'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa87c506",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa87c506",
        "outputId": "ec0bc799-7cba-4f0b-80a8-8605211e34a9"
      },
      "outputs": [],
      "source": [
        "df['CHANNELID_SPLR'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "969f9aa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "969f9aa2",
        "outputId": "0eff8c22-fc62-40a3-d336-f3449c641045"
      },
      "outputs": [],
      "source": [
        "df['CHANNELNAME_SPLR'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8412f38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "f8412f38",
        "outputId": "f0eaa953-81e7-4fbd-957c-71e390f11c40"
      },
      "outputs": [],
      "source": [
        "df[df['CHANNELNAME_SPLR'] == 'Salon Kecantikan']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340ebf56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "340ebf56",
        "outputId": "da223911-f6ef-4858-e209-c1daabf83005"
      },
      "outputs": [],
      "source": [
        "df['CHANNELNAME_SPLR'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9c6ad3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9c6ad3",
        "outputId": "b5de6fd2-b091-40ab-d804-9092056b3e25"
      },
      "outputs": [],
      "source": [
        "df['CustomerID'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46271a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46271a9",
        "outputId": "74c9a3c7-54d3-4d09-ee8e-96759bac3c99"
      },
      "outputs": [],
      "source": [
        "df['oldCUSTID'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002645cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "002645cb",
        "outputId": "c0b96029-bf59-42b4-e961-c6c2a6100a0e"
      },
      "outputs": [],
      "source": [
        "df['PRODUCT'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3961afc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3961afc",
        "outputId": "20b2313a-cd29-438a-ebbc-d357b4db7c2c"
      },
      "outputs": [],
      "source": [
        "df['PRODUCT_CATEGORY'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edb0714",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9edb0714",
        "outputId": "ccf74839-db81-4017-88bd-7883082ce36c"
      },
      "outputs": [],
      "source": [
        "df['PRODUCT_CATEGORY'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec3d180",
      "metadata": {
        "id": "4ec3d180"
      },
      "outputs": [],
      "source": [
        "df['InvoiceDate'] = df['InvoiceDate'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7835c63a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7835c63a",
        "outputId": "059258af-c2e2-454f-ed76-8900578f7ff1"
      },
      "outputs": [],
      "source": [
        "df['PROVINSI'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f8bd38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d2f8bd38",
        "outputId": "2becca50-c7c4-4e72-b7ee-15b7c6c63dfb"
      },
      "outputs": [],
      "source": [
        "df[df['PROVINSI'].isna()]['KOTA'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59db6072",
      "metadata": {},
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e79aa6",
      "metadata": {},
      "source": [
        "## Normalize City Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931578fd",
      "metadata": {
        "id": "931578fd"
      },
      "outputs": [],
      "source": [
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SOLO 08960358885', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'NGUNTORONADI', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'JATIROTO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'MERBAUNG-KLATEN SELA', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BATURETNO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'PRMBNAN KLT', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'NGAWEN KLATEN', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BULIKERTO WONOGIRI', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'KARTASURA', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'NGADIROJO WONOGIRI', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'TIRTOMOYO WONOGIRI', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'MOJOSONGO SURAKARTA', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'KLATEN UTARA', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'POLOKERTO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'KARTOSURO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SURAKARTA', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SUKOHARJO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'KARANGANYAR', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BOYOLALI', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SOLO', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SANGATA', 'PROVINSI'] = 'KALIMANTAN TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SRAGEN', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BONDOWOSO', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'WONOGIRI', 'PROVINSI'] = 'JAWA TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SITUBONDO', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'JEMBER', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BANYUWANGI', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'SAMPIT', 'PROVINSI'] = 'KALIMANTAN TENGAH'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'BONTANG', 'PROVINSI'] = 'KALIMANTAN TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'LUMAJANG', 'PROVINSI'] = 'JAWA TIMUR'\n",
        "df.loc[df['KOTA'].astype(str).str.strip().str.upper() == 'KLATEN', 'PROVINSI'] = 'JAWA TENGAH'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c3d906",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "f2c3d906",
        "outputId": "aaf69d59-1137-4884-b034-b400c91dce05"
      },
      "outputs": [],
      "source": [
        "df[df['KOTA'].isna() & df['PROVINSI'].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d78cef",
      "metadata": {},
      "source": [
        "## Take Not Null Values of City & Province"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bccc875",
      "metadata": {
        "id": "2bccc875"
      },
      "outputs": [],
      "source": [
        "df = df[df['KOTA'].notna() | df['PROVINSI'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c252c45",
      "metadata": {},
      "source": [
        "## Casefold the Province"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e23122",
      "metadata": {
        "id": "b4e23122"
      },
      "outputs": [],
      "source": [
        "df['PROVINSI'] = df['PROVINSI'].str.strip().str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144150cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "144150cd",
        "outputId": "d0e52dd5-dd1b-40f0-941d-9955032ac99d"
      },
      "outputs": [],
      "source": [
        "df['PROVINSI'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "631aa6b8",
      "metadata": {},
      "source": [
        "## Normalize Province Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9633fa8b",
      "metadata": {
        "id": "9633fa8b"
      },
      "outputs": [],
      "source": [
        "df['PROVINSI'] = df['PROVINSI'].replace('KAL-BAR', 'KALIMANTAN BARAT')\n",
        "df['PROVINSI'] = df['PROVINSI'].replace('KAL-SEL', 'KALIMANTAN SELATAN')\n",
        "df['PROVINSI'] = df['PROVINSI'].replace('KALTENG', 'KALIMANTAN TENGAH')\n",
        "df['PROVINSI'] = df['PROVINSI'].replace('JAWATENGAH', 'JAWA TENGAH')\n",
        "df['PROVINSI'] = df['PROVINSI'].replace('DIY', 'DI YOGYAKARTA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbb3563",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['PROVINSI'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f02374e",
      "metadata": {},
      "source": [
        "## Make Island Column from Province Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230bdd2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "map_pulau = {\n",
        "    'KALIMANTAN TIMUR': 'KALIMANTAN & SULAWESI',\n",
        "    'KALIMANTAN BARAT': 'KALIMANTAN & SULAWESI',\n",
        "    'KALIMANTAN SELATAN': 'KALIMANTAN & SULAWESI',\n",
        "    'KALIMANTAN TENGAH': 'KALIMANTAN & SULAWESI',\n",
        "    'JAWA TENGAH': 'JAWA, BALI, & NT',\n",
        "    'JAWA TIMUR': 'JAWA, BALI, & NT',\n",
        "    'JAWA BARAT': 'JAWA, BALI, & NT',\n",
        "    'BANTEN' : 'JAWA, BALI, & NT',\n",
        "    'DI YOGYAKARTA': 'JAWA, BALI, & NT',\n",
        "    'BALI' : 'JAWA, BALI, & NT',\n",
        "    'NUSA TENGGARA BARAT': 'JAWA, BALI, & NT',\n",
        "    'BANGKA BELITUNG': 'SUMATERA & RIAU',\n",
        "    'SUMATERA SELATAN': 'SUMATERA & RIAU',\n",
        "    'SUMATERA UTARA': 'SUMATERA & RIAU',\n",
        "    'SUMATERA BARAT': 'SUMATERA & RIAU',\n",
        "    'RIAU': 'SUMATERA & RIAU',\n",
        "    'LAMPUNG': 'SUMATERA & RIAU',\n",
        "    'JAMBI': 'SUMATERA & RIAU',\n",
        "    'KEPULAUAN RIAU': 'SUMATERA & RIAU',\n",
        "    'LAMPUNG': 'SUMATERA & RIAU',\n",
        "    'KEPULAUAN RIAU': 'SUMATERA & RIAU',\n",
        "    'RIAU': 'SUMATERA & RIAU',\n",
        "    'SULAWESI SELATAN': 'KALIMANTAN & SULAWESI',\n",
        "    'SULAWESI UTARA': 'KALIMANTAN & SULAWESI',\n",
        "    'SULAWESI TENGGARA': 'KALIMANTAN & SULAWESI',\n",
        "    'SULAWESI TENGAH': 'KALIMANTAN & SULAWESI',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead5d279",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['PULAU'] = df['PROVINSI'].map(map_pulau)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99921396",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99921396",
        "outputId": "4bec35d9-ff89-41d6-f4b5-36a8e0aa4932"
      },
      "outputs": [],
      "source": [
        "start = df['InvoiceDate'].min()\n",
        "end = df['InvoiceDate'].max()\n",
        "all_dates = set([start + timedelta(days=x) for x in range((end-start).days + 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f25ea0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f25ea0",
        "outputId": "6dc2b7b3-2a0c-4df5-8dbe-7701527d974c"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa50fa6",
      "metadata": {},
      "source": [
        "## Fix the Minus Quanitity Sold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6f1c9a",
      "metadata": {
        "id": "3c6f1c9a"
      },
      "outputs": [],
      "source": [
        "df['Quantity'] = df['Quantity'].apply(lambda x : -x if x < 0 else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a594d90",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ba254de",
      "metadata": {},
      "source": [
        "## Plot Category By General (Indonesia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a4351c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f3a4351c",
        "outputId": "fbfccba8-35c6-44d5-dc2f-734f9f80836f"
      },
      "outputs": [],
      "source": [
        "categories = sorted(df['PRODUCT_CATEGORY'].unique())\n",
        "all_dates = pd.date_range(start=pd.to_datetime(start), end=pd.to_datetime(end))\n",
        "\n",
        "for product_cat in categories:\n",
        "    tmp = df[df['PRODUCT_CATEGORY'] == product_cat].copy()\n",
        "\n",
        "    if tmp.empty:\n",
        "        continue\n",
        "\n",
        "    tmp['InvoiceDate'] = pd.to_datetime(tmp['InvoiceDate'])\n",
        "\n",
        "    # A. DATA HARIAN\n",
        "    daily = tmp.groupby(tmp['InvoiceDate'].dt.date)['Quantity'].sum().reset_index()\n",
        "    daily.columns = ['InvoiceDate', 'qty_sum']\n",
        "    daily.index = pd.to_datetime(daily['InvoiceDate'])\n",
        "    daily_full = daily.reindex(all_dates, method=None)\n",
        "\n",
        "    # C. DATA MINGGUAN\n",
        "    weekly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='W'))['Quantity'].sum()\n",
        "    # B. DATA BULANAN\n",
        "    monthly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='M'))['Quantity'].sum()\n",
        "\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
        "\n",
        "    # Daily\n",
        "    axes[0].plot(daily_full.index, daily_full['qty_sum'], color='tab:blue', linestyle='-', linewidth=1)\n",
        "    axes[0].set_title(f'Daily Quantity: {product_cat}', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Date')\n",
        "    axes[0].set_ylabel('Quantity')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Weekly\n",
        "    axes[2].plot(weekly.index, weekly.values, color='tab:green', marker='s', linestyle='-', linewidth=2)\n",
        "    axes[2].set_title(f'Weekly Quantity: {product_cat}', fontsize=14, fontweight='bold')\n",
        "    axes[2].set_xlabel('Date')\n",
        "    axes[2].set_ylabel('Quantity')\n",
        "    axes[2].grid(alpha=0.3)\n",
        "    \n",
        "    # Monthly\n",
        "    axes[1].plot(monthly.index, monthly.values, color='tab:red', marker='o', linestyle='-', linewidth=2)\n",
        "    axes[1].set_title(f'Monthly Quantity: {product_cat}', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Date')\n",
        "    axes[1].set_ylabel('Quantity')\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a58c75",
      "metadata": {},
      "source": [
        "If plotted by General (Indonesia), the movement plot are not significantly cause a pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320dbd3d",
      "metadata": {},
      "source": [
        "## Plot Category By Province"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49a9d29",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = df.dropna(subset=['PROVINSI'])\n",
        "# df['PROVINSI'] = df['PROVINSI'].astype(str)\n",
        "# df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# if 'start' not in locals(): start = df['InvoiceDate'].min()\n",
        "# if 'end' not in locals(): end = df['InvoiceDate'].max()\n",
        "\n",
        "# all_dates = pd.date_range(start=start, end=end)\n",
        "\n",
        "# list_provinsi = sorted(df['PROVINSI'].unique())\n",
        "\n",
        "# for provinsi in list_provinsi:\n",
        "#     df_prov = df[df['PROVINSI'] == provinsi].copy()\n",
        "#     categories = sorted(df_prov['PRODUCT_CATEGORY'].unique())\n",
        "    \n",
        "#     for product_cat in categories:\n",
        "#         tmp = df_prov[df_prov['PRODUCT_CATEGORY'] == product_cat].copy()\n",
        "#         if tmp.empty:\n",
        "#             continue\n",
        "\n",
        "#         daily = tmp.groupby(tmp['InvoiceDate'].dt.normalize())['Quantity'].sum()\n",
        "#         daily_full = daily.reindex(all_dates, fill_value=0)\n",
        "\n",
        "#         weekly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='W'))['Quantity'].sum()\n",
        "#         monthly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='M'))['Quantity'].sum()\n",
        "\n",
        "#         fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "#         plt.suptitle(f\"PROVINSI: {provinsi} | KATEGORI: {product_cat}\", fontsize=16, fontweight='bold', y=1.05)\n",
        "\n",
        "#         axes[0].plot(daily_full.index, daily_full.values, linewidth=1, alpha=0.8)\n",
        "#         axes[0].set_title('Daily Quantity', fontsize=12, fontweight='bold')\n",
        "#         axes[0].set_xlabel('Date')\n",
        "#         axes[0].set_ylabel('Qty')\n",
        "#         axes[0].grid(alpha=0.3)\n",
        "#         axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         axes[1].plot(weekly.index, weekly.values, marker='s', linestyle='-', linewidth=2)\n",
        "#         axes[1].set_title('Weekly Quantity', fontsize=12, fontweight='bold')\n",
        "#         axes[1].set_xlabel('Date')\n",
        "#         axes[1].grid(alpha=0.3)\n",
        "#         axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         axes[2].plot(monthly.index, monthly.values, marker='o', linestyle='-', linewidth=2)\n",
        "#         axes[2].set_title('Monthly Quantity', fontsize=12, fontweight='bold')\n",
        "#         axes[2].set_xlabel('Date')\n",
        "#         axes[2].grid(alpha=0.3)\n",
        "#         axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "568ace2c",
      "metadata": {},
      "source": [
        "If we grouping by Province, it's showed that there are so many days/weeks that has zero sales, it's too noice.. But, if we use Monthly Sales by Province, the data is too short"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac010f0",
      "metadata": {},
      "source": [
        "## Plot Category By Pulau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f6476c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['PULAU'])\n",
        "df['PULAU'] = df['PULAU'].astype(str)\n",
        "\n",
        "if 'start' not in locals(): start = df['InvoiceDate'].min()\n",
        "if 'end' not in locals(): end = df['InvoiceDate'].max()\n",
        "\n",
        "all_dates = pd.date_range(start=pd.to_datetime(start), end=pd.to_datetime(end))\n",
        "\n",
        "list_pulau = sorted(df['PULAU'].unique())\n",
        "\n",
        "for pulau in list_pulau:\n",
        "    df_pulau = df[df['PULAU'] == pulau].copy()\n",
        "    categories = sorted(df_pulau['PRODUCT_CATEGORY'].unique())\n",
        "    \n",
        "    for product_cat in categories:\n",
        "        tmp = df_pulau[df_pulau['PRODUCT_CATEGORY'] == product_cat].copy()\n",
        "        if tmp.empty:\n",
        "            continue\n",
        "    \n",
        "        daily = tmp.groupby(tmp['InvoiceDate'].dt.date)['Quantity'].sum()\n",
        "        daily.index = pd.to_datetime(daily.index)\n",
        "    \n",
        "        daily_full = daily.reindex(all_dates, fill_value=0) \n",
        "        weekly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='W'))['Quantity'].sum()\n",
        "        monthly = tmp.groupby(pd.Grouper(key='InvoiceDate', freq='M'))['Quantity'].sum()\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "        plt.suptitle(f\"PULAU: {pulau} | KATEGORI: {product_cat}\", fontsize=16, fontweight='bold', y=1.05)\n",
        "    \n",
        "        axes[0].plot(daily_full.index, daily_full.values, color='tab:blue', linewidth=1, alpha=0.8)\n",
        "        axes[0].set_title('Daily Quantity', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Date')\n",
        "        axes[0].set_ylabel('Qty')\n",
        "        axes[0].grid(alpha=0.3)\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "        axes[1].plot(weekly.index, weekly.values, color='tab:green', marker='s', linestyle='-', linewidth=2)\n",
        "        axes[1].set_title('Weekly Quantity', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Date')\n",
        "        axes[1].grid(alpha=0.3)\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        axes[2].plot(monthly.index, monthly.values, color='tab:red', marker='o', linestyle='-', linewidth=2)\n",
        "        axes[2].set_title('Monthly Quantity', fontsize=12, fontweight='bold')\n",
        "        axes[2].set_xlabel('Date')\n",
        "        axes[2].grid(alpha=0.3)\n",
        "        axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa48ab75",
      "metadata": {},
      "source": [
        "Grouping it by Pulau in Weekly Sales is the best solution, cause it's serve a long trends, and serve a good trends too"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c2ef72b",
      "metadata": {},
      "source": [
        "## Payday Impact on Trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d4bb25",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_palette(\"husl\")\n",
        "\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "def is_payday_week(date):\n",
        "    day = date.day\n",
        "    return 1 if (day >= 25 or day <= 5) else 0\n",
        "\n",
        "df['Is_Payday_Week'] = df['InvoiceDate'].apply(is_payday_week)\n",
        "df['Week'] = df['InvoiceDate'].dt.isocalendar().week\n",
        "df['Month'] = df['InvoiceDate'].dt.month\n",
        "\n",
        "weekly_agg = df.groupby([pd.Grouper(key='InvoiceDate', freq='W'), 'PULAU']).agg({\n",
        "    'Quantity': 'sum',\n",
        "    'Is_Payday_Week': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "fig.suptitle('ANALISIS VOLATILITAS PERMINTAAN PER WILAYAH PULAU', fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "ax1 = axes[0, 0]\n",
        "pulau_order = weekly_agg.groupby('PULAU')['Quantity'].median().sort_values(ascending=False).index\n",
        "sns.boxplot(data=weekly_agg, x='PULAU', y='Quantity', order=pulau_order, ax=ax1, palette='Set2')\n",
        "ax1.set_title('Distribusi Volume Transaksi Mingguan per Pulau', fontweight='bold', fontsize=12)\n",
        "ax1.set_xlabel('Pulau')\n",
        "ax1.set_ylabel('Quantity (Unit)')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "volatility = weekly_agg.groupby('PULAU')['Quantity'].agg(['mean', 'std'])\n",
        "volatility['CV'] = (volatility['std'] / volatility['mean']) * 100\n",
        "volatility = volatility.sort_values('CV', ascending=False)\n",
        "\n",
        "colors = ['red' if cv > 50 else 'orange' if cv > 30 else 'green' for cv in volatility['CV']]\n",
        "ax2.barh(volatility.index, volatility['CV'], color=colors, edgecolor='black')\n",
        "ax2.set_title('Coefficient of Variation (Volatilitas Permintaan)', fontweight='bold', fontsize=12)\n",
        "ax2.set_xlabel('CV (%)')\n",
        "ax2.set_ylabel('Pulau')\n",
        "ax2.axvline(x=50, color='red', linestyle='--', linewidth=1, label='High Volatility (>50%)')\n",
        "ax2.axvline(x=30, color='orange', linestyle='--', linewidth=1, label='Medium Volatility (30-50%)')\n",
        "ax2.legend(fontsize=9)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "ax3 = axes[1, 0]\n",
        "payday_comparison = weekly_agg.groupby(['PULAU', 'Is_Payday_Week'])['Quantity'].mean().unstack(fill_value=0)\n",
        "payday_comparison['Lift'] = ((payday_comparison[1] - payday_comparison[0]) / payday_comparison[0]) * 100\n",
        "payday_comparison = payday_comparison.sort_values('Lift', ascending=False)\n",
        "\n",
        "x = np.arange(len(payday_comparison))\n",
        "width = 0.35\n",
        "ax3.bar(x - width/2, payday_comparison[0], width, label='Non-Payday Week', color='skyblue', edgecolor='black')\n",
        "ax3.bar(x + width/2, payday_comparison[1], width, label='Payday Week', color='salmon', edgecolor='black')\n",
        "ax3.set_title('Efek Payday: Perbandingan Volume Transaksi', fontweight='bold', fontsize=12)\n",
        "ax3.set_xlabel('Pulau')\n",
        "ax3.set_ylabel('Avg Quantity (Unit)')\n",
        "ax3.set_xticks(x)\n",
        "ax3.set_xticklabels(payday_comparison.index, rotation=45, ha='right')\n",
        "ax3.legend()\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "colors_lift = ['darkgreen' if lift > 20 else 'yellowgreen' if lift > 10 else 'gray' for lift in payday_comparison['Lift']]\n",
        "ax4.barh(payday_comparison.index, payday_comparison['Lift'], color=colors_lift, edgecolor='black')\n",
        "ax4.set_title('Payday Lift Effect (%)', fontweight='bold', fontsize=12)\n",
        "ax4.set_xlabel('% Increase During Payday')\n",
        "ax4.set_ylabel('Pulau')\n",
        "ax4.axvline(x=20, color='darkgreen', linestyle='--', linewidth=1, label='Strong Effect (>20%)')\n",
        "ax4.axvline(x=10, color='yellowgreen', linestyle='--', linewidth=1, label='Moderate Effect (10-20%)')\n",
        "ax4.legend(fontsize=9)\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89facbaa",
      "metadata": {},
      "source": [
        "## Seasonality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea958048",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig2, axes2 = plt.subplots(3, 1, figsize=(18, 14))\n",
        "fig2.suptitle('KARAKTERISTIK MUSIMAN: POLA TREN MINGGUAN PER PULAU', fontsize=16, fontweight='bold')\n",
        "\n",
        "top_3_pulau = weekly_agg.groupby('PULAU')['Quantity'].sum().nlargest(3).index\n",
        "\n",
        "for idx, pulau in enumerate(top_3_pulau):\n",
        "    ax = axes2[idx]\n",
        "    \n",
        "    subset = weekly_agg[weekly_agg['PULAU'] == pulau].copy()\n",
        "    subset = subset.sort_values('InvoiceDate')\n",
        "    \n",
        "    ax.plot(subset['InvoiceDate'], subset['Quantity'], marker='o', linewidth=2, markersize=4, label='Quantity')\n",
        "    \n",
        "    payday_weeks = subset[subset['Is_Payday_Week'] == 1]\n",
        "    ax.scatter(payday_weeks['InvoiceDate'], payday_weeks['Quantity'], \n",
        "               color='red', s=100, zorder=5, label='Payday Week', marker='^', edgecolors='black')\n",
        "    \n",
        "    subset['Rolling_Avg'] = subset['Quantity'].rolling(window=4, min_periods=1).mean()\n",
        "    ax.plot(subset['InvoiceDate'], subset['Rolling_Avg'], linestyle='--', linewidth=2, \n",
        "            color='orange', label='4-Week Moving Avg', alpha=0.7)\n",
        "    \n",
        "    ax.set_title(f'Pulau: {pulau}', fontweight='bold', fontsize=12)\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Quantity (Unit)')\n",
        "    ax.legend(loc='upper left')\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13f7403",
      "metadata": {},
      "source": [
        "## Heatmap Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77cff1be",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig3, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "heatmap_data = weekly_agg.pivot_table(index='PULAU', columns=weekly_agg['InvoiceDate'].dt.strftime('%Y-%W'), \n",
        "                                       values='Quantity', aggfunc='sum', fill_value=0)\n",
        "\n",
        "heatmap_normalized = heatmap_data.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
        "\n",
        "sns.heatmap(heatmap_normalized, cmap='RdYlGn', center=0, annot=False, fmt='.1f', \n",
        "            linewidths=0.5, cbar_kws={'label': 'Z-Score (Deviation from Mean)'}, ax=ax)\n",
        "ax.set_title('HEATMAP: Peak Demand per Minggu & Pulau (Z-Score Normalized)', fontweight='bold', fontsize=14)\n",
        "ax.set_xlabel('Week (Year-Week)')\n",
        "ax.set_ylabel('Pulau')\n",
        "plt.xticks(rotation=90, fontsize=8)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" RINGKASAN STATISTIK VOLATILITAS PER PULAU\")\n",
        "print(\"=\"*70)\n",
        "summary = volatility[['mean', 'std', 'CV']].copy()\n",
        "summary.columns = ['Avg Weekly Vol', 'Std Dev', 'Volatility (CV%)']\n",
        "summary['Payday Lift (%)'] = payday_comparison['Lift']\n",
        "print(summary.sort_values('Volatility (CV%)', ascending=False).to_string(float_format='%.2f'))\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c76ad2c0",
      "metadata": {},
      "source": [
        "## Product Frequent Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9bb75a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\" ANALISIS FREKUENSI KATEGORI PRODUK - ANCHOR PRODUCTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "category_freq_global = df['PRODUCT_CATEGORY'].value_counts()\n",
        "print(\"\\nðŸ“Š TOP 15 KATEGORI PRODUK (Global - Semua Pulau):\")\n",
        "print(category_freq_global.head(15))\n",
        "\n",
        "penetrasi_pulau = df.groupby('PRODUCT_CATEGORY')['PULAU'].nunique().reset_index()\n",
        "penetrasi_pulau.columns = ['PRODUCT_CATEGORY', 'Num_Pulau']\n",
        "penetrasi_pulau['Penetrasi_%'] = (penetrasi_pulau['Num_Pulau'] / df['PULAU'].nunique()) * 100\n",
        "\n",
        "anchor_products = category_freq_global.reset_index()\n",
        "anchor_products.columns = ['PRODUCT_CATEGORY', 'Frequency']\n",
        "anchor_products = anchor_products.merge(penetrasi_pulau, on='PRODUCT_CATEGORY')\n",
        "anchor_products = anchor_products.sort_values(['Penetrasi_%', 'Frequency'], ascending=[False, False])\n",
        "\n",
        "print(\"\\nðŸŽ¯ ANCHOR PRODUCTS (Penetrasi Pasar Tinggi di Semua Pulau):\")\n",
        "anchor_threshold = anchor_products[anchor_products['Penetrasi_%'] >= 66.67]  \n",
        "print(anchor_threshold[['PRODUCT_CATEGORY', 'Frequency', 'Num_Pulau', 'Penetrasi_%']].head(20))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "top_20_freq = anchor_products.head(20)\n",
        "axes[0].barh(top_20_freq['PRODUCT_CATEGORY'], top_20_freq['Frequency'], color='steelblue', edgecolor='black')\n",
        "axes[0].set_xlabel('Jumlah Transaksi', fontsize=11, fontweight='bold')\n",
        "axes[0].set_title('Top 20 Kategori Produk (Frekuensi)', fontsize=12, fontweight='bold')\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "colors_penetrasi = ['darkgreen' if p == 100 else 'orange' if p >= 66.67 else 'lightcoral' \n",
        "                    for p in top_20_freq['Penetrasi_%']]\n",
        "axes[1].barh(top_20_freq['PRODUCT_CATEGORY'], top_20_freq['Penetrasi_%'], color=colors_penetrasi, edgecolor='black')\n",
        "axes[1].set_xlabel('Penetrasi Pasar (%)', fontsize=11, fontweight='bold')\n",
        "axes[1].set_title('Top 20 Kategori Produk (Penetrasi Pasar)', fontsize=12, fontweight='bold')\n",
        "axes[1].axvline(x=100, color='darkgreen', linestyle='--', linewidth=2, label='100% (Semua Pulau)')\n",
        "axes[1].axvline(x=66.67, color='orange', linestyle='--', linewidth=2, label='67% (Anchor Threshold)')\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].legend()\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b702a392",
      "metadata": {},
      "source": [
        "## Buying Pattern Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272dc885",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETEKSI POLA PEMBELIAN SERENTAK (Co-occurrence Analysis)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "co_purchase_pairs = []\n",
        "invoice_products = df.groupby('InvoiceNo')['PRODUCT_CATEGORY'].apply(list).reset_index()\n",
        "\n",
        "print(f\"\\nTotal Invoice: {len(invoice_products)}\")\n",
        "print(f\"Invoice dengan Multiple Items (Bundling): {(invoice_products['PRODUCT_CATEGORY'].apply(len) > 1).sum()}\")\n",
        "\n",
        "for items in invoice_products['PRODUCT_CATEGORY']:\n",
        "    if len(items) >= 2:\n",
        "        unique_items = list(set(items)) \n",
        "        \n",
        "        if len(unique_items) >= 2:\n",
        "            for i in range(len(unique_items)):\n",
        "                for j in range(i + 1, len(unique_items)):\n",
        "                    pair = tuple(sorted([unique_items[i], unique_items[j]]))\n",
        "                    co_purchase_pairs.append(pair)\n",
        "\n",
        "pair_counter = Counter(co_purchase_pairs)\n",
        "top_pairs = pair_counter.most_common(20)\n",
        "\n",
        "print(\"\\nTOP 20 PASANGAN PRODUK (Co-occurrence dalam 1 Invoice):\")\n",
        "print(\"-\" * 80)\n",
        "for idx, (pair, count) in enumerate(top_pairs, 1):\n",
        "    print(f\"{idx:2d}. {pair[0]:25s} + {pair[1]:25s} : {count:5d} transaksi\")\n",
        "\n",
        "co_purchase_df = pd.DataFrame([\n",
        "    {'Product_1': pair[0], 'Product_2': pair[1], 'Co_Purchase_Count': count}\n",
        "    for pair, count in top_pairs\n",
        "])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "pair_labels = [f\"{p[0][:15]}...\\n+ {p[1][:15]}...\" for p, c in top_pairs]\n",
        "pair_counts = [c for p, c in top_pairs]\n",
        "colors_pairs = plt.cm.viridis(np.linspace(0, 1, len(top_pairs)))\n",
        "\n",
        "ax.barh(range(len(top_pairs)), pair_counts, color=colors_pairs, edgecolor='black')\n",
        "ax.set_yticks(range(len(top_pairs)))\n",
        "ax.set_yticklabels(pair_labels, fontsize=9)\n",
        "ax.set_xlabel('Frekuensi Co-Purchase', fontsize=11, fontweight='bold')\n",
        "ax.set_title('Top 20 Pasangan Produk yang Dibeli Bersamaan', fontsize=13, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfd0493e",
      "metadata": {},
      "source": [
        "## Pruning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a493133f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" 3. VALIDASI PRUNING DATA - EFISIENSI MEMORI\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "category_transaction_count = df['PRODUCT_CATEGORY'].value_counts()\n",
        "\n",
        "PRUNING_THRESHOLD = 5\n",
        "\n",
        "prune_candidates = category_transaction_count[category_transaction_count < PRUNING_THRESHOLD]\n",
        "keep_products = category_transaction_count[category_transaction_count >= PRUNING_THRESHOLD]\n",
        "\n",
        "print(f\"\\nSTATISTIK PRUNING:\")\n",
        "print(f\"   Total Kategori Unik: {len(category_transaction_count)}\")\n",
        "print(f\"   Kategori dengan Frekuensi >= {PRUNING_THRESHOLD}: {len(keep_products)}\")\n",
        "print(f\"   Kategori dengan Frekuensi < {PRUNING_THRESHOLD} (PRUNED): {len(prune_candidates)}\")\n",
        "\n",
        "print(f\"\\nPRODUK DENGAN FREKUENSI SANGAT RENDAH (< {PRUNING_THRESHOLD} transaksi):\")\n",
        "print(\"-\" * 80)\n",
        "if not prune_candidates.empty:\n",
        "    for product, freq in prune_candidates.items():\n",
        "        print(f\"   {product:35s} : {freq:3d} transaksi\")\n",
        "else:\n",
        "    print(\"   (Tidak ada produk dengan frekuensi < 5)\")\n",
        "\n",
        "total_rows = len(df)\n",
        "rows_to_prune = df[df['PRODUCT_CATEGORY'].isin(prune_candidates.index)].shape[0]\n",
        "pruning_ratio = (rows_to_prune / total_rows) * 100\n",
        "\n",
        "print(f\"\\nESTIMASI EFISIENSI MEMORI:\")\n",
        "print(f\"   Total Baris Dataset: {total_rows:,}\")\n",
        "print(f\"   Baris yang Akan Di-Prune: {rows_to_prune:,} ({pruning_ratio:.2f}%)\")\n",
        "print(f\"   Baris Setelah Pruning: {total_rows - rows_to_prune:,}\")\n",
        "\n",
        "print(f\"\\nVALIDASI SUPPORT THRESHOLD untuk Market Basket Analysis:\")\n",
        "print(f\"   Min Support (1% default): {len(df) * 0.01:.0f} transaksi\")\n",
        "print(f\"   Min Support (0.1%): {len(df) * 0.001:.0f} transaksi\")\n",
        "print(f\"   Produk dengan < {PRUNING_THRESHOLD} transaksi TIDAK akan lolos support 1%\")\n",
        "print(f\"   âžœ Pruning ini AMAN untuk dilakukan di backend FastAPI\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "axes[0].hist(category_transaction_count.values, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(x=PRUNING_THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'Pruning Threshold ({PRUNING_THRESHOLD})')\n",
        "axes[0].set_xlabel('Frekuensi Transaksi', fontsize=11, fontweight='bold')\n",
        "axes[0].set_ylabel('Jumlah Kategori Produk', fontsize=11, fontweight='bold')\n",
        "axes[0].set_title('Distribusi Frekuensi Kategori Produk (Semua)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_yscale('log')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "before_after = pd.DataFrame({\n",
        "    'Status': ['Keep\\n(Freq >= 5)', 'Prune\\n(Freq < 5)'],\n",
        "    'Row_Count': [total_rows - rows_to_prune, rows_to_prune],\n",
        "    'Product_Count': [len(keep_products), len(prune_candidates)]\n",
        "})\n",
        "\n",
        "ax2 = axes[1]\n",
        "colors_pie = ['#2ecc71', '#e74c3c']\n",
        "wedges, texts, autotexts = ax2.pie(before_after['Row_Count'], labels=before_after['Status'], \n",
        "                                     autopct='%1.1f%%', colors=colors_pie, startangle=90, \n",
        "                                     explode=(0.05, 0.05), textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
        "ax2.set_title(f'Efek Pruning pada Total Baris Dataset', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b3ad5f",
      "metadata": {},
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dee5325",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pulau = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2df7d2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_apriori = df_pulau.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e950bbbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pulau = df.drop(['BRANCH_SPLR', 'BRANCHNAME_SPLR',\n",
        "    'warehouseProductsID', 'BARCODEID', 'StockCode', 'PRODUCT', 'UnitPrice', 'oldCUSTID',\n",
        "    'CustomerID', 'CUSTNAME', 'ADDRESS', 'KOTA', 'PROVINSI', 'NEGARA',\n",
        "    'CHANNELID_SPLR', 'CHANNELNAME_SPLR', 'SUBDISTID', 'SUBDIST_NAME', 'UnitPriceRupiah'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "767d34bb",
      "metadata": {
        "id": "767d34bb"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['InvoiceNo', 'BRANCH_SPLR', 'BRANCHNAME_SPLR',\n",
        "    'warehouseProductsID', 'BARCODEID', 'StockCode', 'PRODUCT', 'UnitPrice', 'oldCUSTID',\n",
        "    'CustomerID', 'CUSTNAME', 'ADDRESS', 'KOTA', 'PROVINSI', 'NEGARA',\n",
        "    'CHANNELID_SPLR', 'CHANNELNAME_SPLR', 'SUBDISTID', 'SUBDIST_NAME', 'UnitPriceRupiah', 'PULAU'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032942df",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pulau['InvoiceDate'] = pd.to_datetime(df_pulau['InvoiceDate'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d05b879a",
      "metadata": {},
      "source": [
        "## Directive LGBM (global predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bUBCAf7hUVs",
      "metadata": {
        "id": "2bUBCAf7hUVs"
      },
      "outputs": [],
      "source": [
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "df_grouped = df.groupby([pd.Grouper(key='InvoiceDate', freq='W'), 'PRODUCT_CATEGORY'])['Quantity'].sum()\n",
        "df_wide = df_grouped.unstack(level='PRODUCT_CATEGORY').resample('W').asfreq()\n",
        "df_interpolated = df_wide.interpolate(method='linear')\n",
        "df = df_interpolated.stack().reset_index()\n",
        "df.columns = ['InvoiceDate', 'PRODUCT_CATEGORY', 'Quantity']\n",
        "df_pivot = df.pivot(index='InvoiceDate', columns='PRODUCT_CATEGORY', values='Quantity')\n",
        "\n",
        "TEST_WEEKS = 12\n",
        "LOOK_BACK = 4 \n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "categories_list = []\n",
        "dates_list = []\n",
        "\n",
        "for category in df_pivot.columns:\n",
        "    series = df_pivot[category].values\n",
        "    series_log = np.log1p(series)\n",
        "    \n",
        "    for i in range(LOOK_BACK, len(series_log) - TEST_WEEKS + 1):\n",
        "        past_window = series_log[i-LOOK_BACK : i]\n",
        "        future_window = series_log[i : i+TEST_WEEKS] \n",
        "        \n",
        "        if len(future_window) < TEST_WEEKS:\n",
        "            continue\n",
        "            \n",
        "        feat_mean = np.mean(past_window)\n",
        "        feat_std = np.std(past_window)\n",
        "    \n",
        "        features = list(past_window) + [feat_mean, feat_std]\n",
        "        \n",
        "        X_all.append(features)\n",
        "        y_all.append(future_window)\n",
        "        categories_list.append(category)\n",
        "        dates_list.append(df_pivot.index[i])\n",
        "\n",
        "X_df = pd.DataFrame(X_all)\n",
        "feat_cols = [f'Lag_{j}' for j in range(LOOK_BACK, 0, -1)] + ['Mean', 'Std']\n",
        "X_df.columns = feat_cols\n",
        "X_df['Category'] = categories_list\n",
        "X_df['Category'] = X_df['Category'].astype('category')\n",
        "X_df['Month'] = pd.to_datetime(dates_list).month\n",
        "\n",
        "y_arr = np.array(y_all)\n",
        "\n",
        "cutoff_date = df_pivot.index[-TEST_WEEKS]\n",
        "is_train = pd.to_datetime(dates_list) < cutoff_date\n",
        "is_test = pd.to_datetime(dates_list) == cutoff_date \n",
        "\n",
        "X_train = X_df[is_train]\n",
        "y_train = y_arr[is_train]\n",
        "X_test = X_df[is_test]\n",
        "y_test = y_arr[is_test] \n",
        "\n",
        "lgbm = LGBMRegressor(n_estimators=500, learning_rate=0.07, num_leaves=20, n_jobs=-1)\n",
        "model = MultiOutputRegressor(lgbm)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_log = model.predict(X_test)\n",
        "\n",
        "y_pred_final = np.expm1(y_pred_log)\n",
        "y_test_final = np.expm1(y_test)\n",
        "\n",
        "test_categories = X_test['Category'].values\n",
        "eval_results = []\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "for i, cat_name in enumerate(test_categories):\n",
        "    actual = y_test_final[i]\n",
        "    pred = y_pred_final[i]\n",
        "    \n",
        "    pred = np.maximum(pred, 0)\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mape = mean_absolute_percentage_error(actual, pred)\n",
        "    mae = mean_absolute_error(actual, pred) \n",
        "    \n",
        "    note = \"\"\n",
        "    if mape > 0.5 and mae < 5:\n",
        "        note = \"(Low Vol)\"\n",
        "    \n",
        "    eval_results.append({\n",
        "        'Category': cat_name,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,          \n",
        "        'MAPE': mape,\n",
        "        'Note': note\n",
        "    })\n",
        "    \n",
        "    if i < 12:\n",
        "        plt.subplot(3, 4, i+1)\n",
        "        weeks = range(1, TEST_WEEKS+1)\n",
        "        plt.plot(weeks, actual, label='Actual', marker='o', color='green')\n",
        "        plt.plot(weeks, pred, label='Pred', marker='x', linestyle='--', color='red')\n",
        "        plt.title(f\"{cat_name}\\nMAPE: {mape:.1%} | MAE: {mae:.1f}\")\n",
        "        plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_eval = pd.DataFrame(eval_results)\n",
        "df_eval['MAPE_Percentage'] = df_eval['MAPE'].apply(lambda x: f\"{x:.2%}\")\n",
        "print(\"\\n=== FINAL RESULTS (LOG TRANSFORMED) ===\")\n",
        "print(df_eval.sort_values(by='MAPE')[['Category', 'MAE', 'MAPE_Percentage', 'Note']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d8e136",
      "metadata": {},
      "source": [
        "## Local Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8630021",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pulau['InvoiceDate'] = pd.to_datetime(df_pulau['InvoiceDate'])\n",
        "df_grouped = df_pulau.groupby([\n",
        "    pd.Grouper(key='InvoiceDate', freq='W'), \n",
        "    'PULAU', \n",
        "    'PRODUCT_CATEGORY'\n",
        "])['Quantity'].sum().reset_index()\n",
        "\n",
        "df_pivot = df_grouped.pivot(index='InvoiceDate', columns=['PULAU', 'PRODUCT_CATEGORY'], values='Quantity')\n",
        "\n",
        "df_pivot = df_pivot.resample('W').asfreq().interpolate(method='linear').fillna(0)\n",
        "\n",
        "df_stacked = df_pivot.stack(level=['PULAU', 'PRODUCT_CATEGORY']).reset_index()\n",
        "df_stacked.columns = ['InvoiceDate', 'PULAU', 'PRODUCT_CATEGORY', 'Quantity']\n",
        "\n",
        "TEST_WEEKS = 10\n",
        "LOOK_BACK = 4\n",
        "\n",
        "def is_payday_week(date):\n",
        "    day = date.day\n",
        "    if day >= 25 or day <= 5:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "meta_info = [] \n",
        "dates_list = []\n",
        "\n",
        "unique_combinations = df_stacked[['PULAU', 'PRODUCT_CATEGORY']].drop_duplicates().values\n",
        "\n",
        "print(\"Sedang memproses Feature Engineering...\")\n",
        "\n",
        "for pulau, category in unique_combinations:\n",
        "    subset = df_stacked[\n",
        "        (df_stacked['PULAU'] == pulau) & \n",
        "        (df_stacked['PRODUCT_CATEGORY'] == category)\n",
        "    ].sort_values('InvoiceDate')\n",
        "    \n",
        "    series_raw = subset['Quantity'].values\n",
        "    \n",
        "    for i in range(LOOK_BACK, len(series_raw) - TEST_WEEKS + 1):\n",
        "        past_window = series_raw[i-LOOK_BACK : i]\n",
        "        future_window = series_raw[i : i+TEST_WEEKS]\n",
        "        \n",
        "        if len(future_window) < TEST_WEEKS:\n",
        "            continue\n",
        "            \n",
        "        feat_mean = np.mean(past_window)\n",
        "        feat_std = np.std(past_window)\n",
        "        \n",
        "        target_date = subset['InvoiceDate'].iloc[i]\n",
        "        feat_payday = is_payday_week(target_date)\n",
        "        \n",
        "        features = list(past_window) + [feat_mean, feat_std, feat_payday]\n",
        "        \n",
        "        X_all.append(features)\n",
        "        y_all.append(future_window)\n",
        "        \n",
        "        meta_info.append({'PULAU': pulau, 'CATEGORY': category})\n",
        "        dates_list.append(target_date)\n",
        "\n",
        "X_df = pd.DataFrame(X_all)\n",
        "feat_cols = [f'Lag_{j}' for j in range(LOOK_BACK, 0, -1)] + ['Mean', 'Std', 'Is_Payday']\n",
        "X_df.columns = feat_cols\n",
        "\n",
        "meta_df = pd.DataFrame(meta_info)\n",
        "X_df['PULAU'] = meta_df['PULAU'].astype('category')\n",
        "X_df['CATEGORY'] = meta_df['CATEGORY'].astype('category')\n",
        "X_df['Month'] = pd.to_datetime(dates_list).month\n",
        "\n",
        "y_arr = np.array(y_all)\n",
        "\n",
        "cutoff_date = df_stacked['InvoiceDate'].max() - pd.Timedelta(weeks=TEST_WEEKS) + pd.Timedelta(days=1)\n",
        "dates_series = pd.to_datetime(dates_list)\n",
        "\n",
        "is_train = dates_series < cutoff_date\n",
        "is_test = dates_series == dates_series.max()\n",
        "\n",
        "X_train = X_df[is_train]\n",
        "y_train = y_arr[is_train]\n",
        "X_test = X_df[is_test]\n",
        "y_test = y_arr[is_test]\n",
        "\n",
        "print(f\"Data Train: {len(X_train)} samples\")\n",
        "print(f\"Data Test : {len(X_test)} samples\")\n",
        "\n",
        "print(\"Melatih Model dengan Objective Tweedie...\")\n",
        "\n",
        "lgbm = LGBMRegressor(\n",
        "    objective='tweedie',            \n",
        "    tweedie_variance_power=1.5,  \n",
        "    n_estimators=1000, \n",
        "    learning_rate=0.05, \n",
        "    num_leaves=31, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model = MultiOutputRegressor(lgbm)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Training Selesai.\")\n",
        "\n",
        "y_pred_final = model.predict(X_test)\n",
        "y_test_final = y_test\n",
        "\n",
        "eval_results = []\n",
        "\n",
        "test_info = meta_df[is_test].reset_index(drop=True)\n",
        "\n",
        "for i in range(len(test_info)):\n",
        "    actual = y_test_final[i]\n",
        "    pred = y_pred_final[i]\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    \n",
        "    if np.sum(actual) == 0:\n",
        "        mape = 0.0\n",
        "    else:\n",
        "        mape = mean_absolute_percentage_error(actual, pred)\n",
        "        \n",
        "    eval_results.append({\n",
        "        'PULAU': test_info.iloc[i]['PULAU'],\n",
        "        'CATEGORY': test_info.iloc[i]['CATEGORY'],\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'MAPE': mape\n",
        "    })\n",
        "\n",
        "unique_pulau = test_info['PULAU'].unique()\n",
        "\n",
        "print(f\"\\nMembuat visualisasi untuk {len(unique_pulau)} Wilayah Pulau...\")\n",
        "\n",
        "for p_name in unique_pulau:\n",
        "    indices = test_info[test_info['PULAU'] == p_name].index\n",
        "    \n",
        "    num_plots = len(indices)\n",
        "    cols = 10                         \n",
        "    rows = math.ceil(num_plots / cols)\n",
        "    \n",
        "    fig, axes = plt.subplots(\n",
        "        rows, \n",
        "        cols, \n",
        "        figsize=(cols * 3, rows * 3),  \n",
        "        dpi=300                        \n",
        "    )\n",
        "    \n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    fig.suptitle(\n",
        "        f\"WILAYAH: {p_name}\\n(Actual vs Tweedie Prediction - 10 Weeks)\",\n",
        "        fontsize=18,\n",
        "        fontweight='bold',\n",
        "        y=1.02\n",
        "    )\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        cat_name = test_info.iloc[idx]['CATEGORY']\n",
        "        \n",
        "        actual = y_test_final[idx]\n",
        "        pred = y_pred_final[idx]\n",
        "        \n",
        "        metric = next(\n",
        "            (item for item in eval_results \n",
        "             if item['PULAU'] == p_name and item['CATEGORY'] == cat_name),\n",
        "            None\n",
        "        )\n",
        "        \n",
        "        mape_val = metric['MAPE']\n",
        "        mae_val = metric['MAE']\n",
        "        \n",
        "        ax = axes[i]\n",
        "        weeks = range(1, TEST_WEEKS + 1)\n",
        "        \n",
        "        ax.plot(\n",
        "            weeks, actual,\n",
        "            label='Actual',\n",
        "            marker='o',\n",
        "            linewidth=1.5,\n",
        "            markersize=3\n",
        "        )\n",
        "        ax.plot(\n",
        "            weeks, pred,\n",
        "            label='Pred',\n",
        "            linestyle='--',\n",
        "            marker='x',\n",
        "            linewidth=1.5,\n",
        "            markersize=3\n",
        "        )\n",
        "        \n",
        "        title_color = 'red' if mape_val > 0.5 else 'black'\n",
        "        ax.set_title(\n",
        "            f\"{cat_name}\\nMAPE:{mape_val:.0%} | MAE:{mae_val:.1f}\",\n",
        "            fontsize=8,\n",
        "            fontweight='bold',\n",
        "            color=title_color\n",
        "        )\n",
        "        \n",
        "        ax.grid(alpha=0.2)\n",
        "        ax.tick_params(axis='both', labelsize=7)\n",
        "        ax.set_xlabel('Week', fontsize=7)\n",
        "        \n",
        "        if i == 0:\n",
        "            ax.legend(fontsize=7, loc='upper left')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"   Selesai plotting {p_name}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371f50b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eval = pd.DataFrame(eval_results)\n",
        "mean_sales_map = {}\n",
        "\n",
        "if 'test_info' in locals() and 'y_test_final' in locals():\n",
        "    for i in range(len(test_info)):\n",
        "        p_name = test_info.iloc[i]['PULAU']\n",
        "        c_name = test_info.iloc[i]['CATEGORY']\n",
        "        mean_val = np.mean(y_test_final[i]) \n",
        "        mean_sales_map[(p_name, c_name)] = mean_val\n",
        "else:\n",
        "    print(\"Warning: Variabel 'test_info' atau 'y_test_final' hilang. Pastikan cell training sudah dijalankan.\")\n",
        "\n",
        "df_eval['Actual_Mean'] = df_eval.apply(lambda x: mean_sales_map.get((x['PULAU'], x['CATEGORY']), 0), axis=1)\n",
        "\n",
        "def get_quality_score(row):\n",
        "    mae = row['MAE']\n",
        "    mean_sales = row['Actual_Mean']\n",
        "    \n",
        "    if mean_sales < 10:\n",
        "        if mae <= 1.0: return \"â­â­â­â­ Excellent\"  \n",
        "        elif mae <= 2.0: return \"â­â­â­ Good\"       \n",
        "        elif mae <= 3.5: return \"â­â­ Fair\"       \n",
        "        else: return \"âš ï¸ Poor\"                  \n",
        "        \n",
        "    else:\n",
        "        if mean_sales == 0: return \"âš ï¸ Poor\"\n",
        "        \n",
        "        ratio = mae / mean_sales\n",
        "        if ratio <= 0.15: return \"â­â­â­â­ Excellent\"     \n",
        "        elif ratio <= 0.25: return \"â­â­â­ Good\"        \n",
        "        elif ratio <= 0.40: return \"â­â­ Fair\"          \n",
        "        else: return \"âš ï¸ Poor\"                          \n",
        "\n",
        "df_eval['Quality'] = df_eval.apply(get_quality_score, axis=1)\n",
        "\n",
        "cols_show = ['PULAU', 'CATEGORY', 'Actual_Mean', 'MAE', 'Quality']\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" LAPORAN KUALITAS MODEL FORECASTING (PER PULAU & KATEGORI)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nâœ… TOP PERFORMERS (Model Sangat Akurat)\")\n",
        "print(\"-\" * 80)\n",
        "good_performance = df_eval[df_eval['Quality'].str.contains(\"Excellent|Good\")]\n",
        "if not good_performance.empty:\n",
        "    print(good_performance[cols_show].sort_values(by=['PULAU', 'Quality'], ascending=[True, True]).to_string(index=False, formatters={\n",
        "        'Actual_Mean': '{:.1f}'.format,\n",
        "        'MAE': '{:.1f}'.format\n",
        "    }))\n",
        "else:\n",
        "    print(\"Tidak ada kategori Excellent/Good.\")\n",
        "\n",
        "print(\"\\n\\nNEEDS ATTENTION (Model Kurang Akurat / Data Volatile)\")\n",
        "print(\"-\" * 80)\n",
        "bad_performance = df_eval[df_eval['Quality'].str.contains(\"Fair|Poor\")]\n",
        "if not bad_performance.empty:\n",
        "    print(bad_performance[cols_show].sort_values(by=['PULAU', 'Quality'], ascending=[True, False]).to_string(index=False, formatters={\n",
        "        'Actual_Mean': '{:.1f}'.format,\n",
        "        'MAE': '{:.1f}'.format\n",
        "    }))\n",
        "else:\n",
        "    print(\"Tidak ada kategori Fair/Poor.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RINGKASAN PERFORMA\")\n",
        "print(\"-\" * 80)\n",
        "print(df_eval['Quality'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62528241",
      "metadata": {},
      "source": [
        "## Global Predict 10 Weeks Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1890fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "df_grouped = df.groupby([pd.Grouper(key='InvoiceDate', freq='W'), 'PRODUCT_CATEGORY'])['Quantity'].sum()\n",
        "df_wide = df_grouped.unstack(level='PRODUCT_CATEGORY').resample('W').asfreq()\n",
        "df_interpolated = df_wide.interpolate(method='linear')\n",
        "df = df_interpolated.stack().reset_index()\n",
        "df.columns = ['InvoiceDate', 'PRODUCT_CATEGORY', 'Quantity']\n",
        "df_pivot = df.pivot(index='InvoiceDate', columns='PRODUCT_CATEGORY', values='Quantity')\n",
        "\n",
        "FORECAST_WEEKS = 10 \n",
        "LOOK_BACK = 4\n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "categories_list = []\n",
        "\n",
        "for category in df_pivot.columns:\n",
        "    series = df_pivot[category].values\n",
        "    series_log = np.log1p(series)\n",
        "    \n",
        "    for i in range(LOOK_BACK, len(series_log) - FORECAST_WEEKS + 1):\n",
        "        past_window = series_log[i-LOOK_BACK : i]\n",
        "        future_window = series_log[i : i+FORECAST_WEEKS]\n",
        "        \n",
        "        if len(future_window) < FORECAST_WEEKS:\n",
        "            continue\n",
        "            \n",
        "        feat_mean = np.mean(past_window)\n",
        "        feat_std = np.std(past_window)\n",
        "        features = list(past_window) + [feat_mean, feat_std]\n",
        "        \n",
        "        X_all.append(features)\n",
        "        y_all.append(future_window)\n",
        "        categories_list.append(category)\n",
        "\n",
        "X_train_full = pd.DataFrame(X_all)\n",
        "feat_cols = [f'Lag_{j}' for j in range(LOOK_BACK, 0, -1)] + ['Mean', 'Std']\n",
        "X_train_full.columns = feat_cols\n",
        "X_train_full['Category'] = categories_list\n",
        "X_train_full['Category'] = X_train_full['Category'].astype('category')\n",
        "y_train_full = np.array(y_all)\n",
        "\n",
        "lgbm = LGBMRegressor(n_estimators=1000, learning_rate=0.07, num_leaves=20, n_jobs=-1)\n",
        "model = MultiOutputRegressor(lgbm)\n",
        "model.fit(X_train_full, y_train_full)\n",
        "\n",
        "last_date = df_pivot.index[-1]\n",
        "future_dates = pd.date_range(start=last_date + pd.Timedelta(weeks=1), periods=FORECAST_WEEKS, freq='W')\n",
        "future_forecasts = {}\n",
        "\n",
        "for category in df_pivot.columns:\n",
        "    latest_series_log = np.log1p(df_pivot[category].values[-LOOK_BACK:])\n",
        "    feat_mean = np.mean(latest_series_log)\n",
        "    feat_std = np.std(latest_series_log)\n",
        "    features = list(latest_series_log) + [feat_mean, feat_std]\n",
        "    \n",
        "    input_row = pd.DataFrame([features], columns=feat_cols)\n",
        "    input_row['Category'] = category\n",
        "    input_row['Category'] = input_row['Category'].astype('category')\n",
        "    \n",
        "    pred_log = model.predict(input_row)[0]\n",
        "    pred_final = np.expm1(pred_log)\n",
        "    future_forecasts[category] = np.maximum(pred_final, 0)\n",
        "\n",
        "df_history_long = df_pivot.reset_index().melt(id_vars='InvoiceDate', var_name='PRODUCT_CATEGORY', value_name='Quantity')\n",
        "df_history_long['Data_Type'] = 'Actual'\n",
        "\n",
        "df_future_wide = pd.DataFrame(future_forecasts, index=future_dates)\n",
        "df_future_long = df_future_wide.reset_index().melt(id_vars='index', var_name='PRODUCT_CATEGORY', value_name='Quantity')\n",
        "df_future_long.rename(columns={'index': 'InvoiceDate'}, inplace=True)\n",
        "df_future_long['Data_Type'] = 'Forecast'\n",
        "\n",
        "df_combined = pd.concat([df_history_long, df_future_long], axis=0).sort_values(by=['PRODUCT_CATEGORY', 'InvoiceDate']).reset_index(drop=True)\n",
        "\n",
        "print(\"=== CONTOH DATA GABUNGAN (Head & Tail) ===\")\n",
        "print(df_combined.head(3))\n",
        "print(\"...\")\n",
        "print(df_combined.tail(3))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "categories_to_plot = df_combined['PRODUCT_CATEGORY'].unique()\n",
        "n_cols = 4\n",
        "n_rows = int(np.ceil(len(categories_to_plot) / n_cols))\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, category in enumerate(categories_to_plot):\n",
        "    ax = axes[i]\n",
        "    subset = df_combined[df_combined['PRODUCT_CATEGORY'] == category]\n",
        "    \n",
        "    actual_data = subset[subset['Data_Type'] == 'Actual']\n",
        "    forecast_data = subset[subset['Data_Type'] == 'Forecast']\n",
        "    \n",
        "    last_actual = actual_data.iloc[-1]\n",
        "    connector = pd.DataFrame([last_actual])\n",
        "    connector['Data_Type'] = 'Forecast' \n",
        "    forecast_plot_data = pd.concat([connector, forecast_data])\n",
        "    \n",
        "    plot_start_date = actual_data['InvoiceDate'].max() - pd.Timedelta(weeks=24)\n",
        "    actual_plot = actual_data[actual_data['InvoiceDate'] >= plot_start_date]\n",
        "    \n",
        "    ax.plot(actual_plot['InvoiceDate'], actual_plot['Quantity'], label='Actual', color='tab:blue', marker='o', markersize=4)\n",
        "    \n",
        "    ax.plot(forecast_plot_data['InvoiceDate'], forecast_plot_data['Quantity'], label='Forecast', color='tab:red', linestyle='--', marker='x', markersize=4, linewidth=2)\n",
        "    \n",
        "    ax.set_title(f\"{category}\", fontsize=10, fontweight='bold')\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
        "    \n",
        "    if i == 0: ax.legend()\n",
        "\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd73dc5",
      "metadata": {},
      "source": [
        "## Local Predict 10 Weeks Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b8b403",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pulau['InvoiceDate'] = pd.to_datetime(df_pulau['InvoiceDate'])\n",
        "df_grouped = df_pulau.groupby([\n",
        "    pd.Grouper(key='InvoiceDate', freq='W'), \n",
        "    'PULAU', \n",
        "    'PRODUCT_CATEGORY'\n",
        "])['Quantity'].sum().reset_index()\n",
        "\n",
        "df_pivot = df_grouped.pivot(index='InvoiceDate', columns=['PULAU', 'PRODUCT_CATEGORY'], values='Quantity')\n",
        "df_pivot = df_pivot.resample('W').asfreq().interpolate(method='linear').fillna(0)\n",
        "df_stacked = df_pivot.stack(level=['PULAU', 'PRODUCT_CATEGORY']).reset_index()\n",
        "df_stacked.columns = ['InvoiceDate', 'PULAU', 'PRODUCT_CATEGORY', 'Quantity']\n",
        "\n",
        "FORECAST_WEEKS = 10  \n",
        "LOOK_BACK = 4        \n",
        "\n",
        "def is_payday_week(date):\n",
        "    day = date.day\n",
        "    if day >= 25 or day <= 5: return 1\n",
        "    return 0\n",
        "\n",
        "unique_pulau = df_stacked['PULAU'].unique()\n",
        "future_dates = pd.date_range(start=df_stacked['InvoiceDate'].max() + pd.Timedelta(weeks=1), periods=FORECAST_WEEKS, freq='W')\n",
        "\n",
        "history_data_list = []\n",
        "forecast_data_list = []\n",
        "\n",
        "print(f\"Memulai Training Full Data & Forecasting {FORECAST_WEEKS} Minggu ke Depan...\")\n",
        "\n",
        "for p_name in unique_pulau:\n",
        "    print(f\"-> Memproses Pulau: {p_name}\")\n",
        "    \n",
        "    df_subset = df_stacked[df_stacked['PULAU'] == p_name].copy()\n",
        "    \n",
        "    df_subset['Data_Type'] = 'Actual'\n",
        "    history_data_list.append(df_subset)\n",
        "    \n",
        "    X_train_all = []\n",
        "    y_train_all = []\n",
        "    meta_train = []\n",
        "    \n",
        "    cats_in_pulau = df_subset['PRODUCT_CATEGORY'].unique()\n",
        "    for category in cats_in_pulau:\n",
        "        sub_cat = df_subset[df_subset['PRODUCT_CATEGORY'] == category].sort_values('InvoiceDate')\n",
        "        series = sub_cat['Quantity'].values\n",
        "        \n",
        "        series_log = np.log1p(series)\n",
        "        \n",
        "        for i in range(LOOK_BACK, len(series_log) - FORECAST_WEEKS + 1):\n",
        "            past_window = series_log[i-LOOK_BACK : i]\n",
        "            future_window = series_log[i : i+FORECAST_WEEKS]\n",
        "            \n",
        "            if len(future_window) < FORECAST_WEEKS: continue\n",
        "            \n",
        "            feat_mean = np.mean(past_window)\n",
        "            feat_std = np.std(past_window)\n",
        "            \n",
        "            target_date = sub_cat['InvoiceDate'].iloc[i]\n",
        "            feat_payday = is_payday_week(target_date)\n",
        "            \n",
        "            features = list(past_window) + [feat_mean, feat_std, feat_payday]\n",
        "            \n",
        "            X_train_all.append(features)\n",
        "            y_train_all.append(future_window)\n",
        "            meta_train.append({'CATEGORY': category})\n",
        "\n",
        "    X_df = pd.DataFrame(X_train_all)\n",
        "    feat_cols = [f'Lag_{j}' for j in range(LOOK_BACK, 0, -1)] + ['Mean', 'Std', 'Is_Payday']\n",
        "    X_df.columns = feat_cols\n",
        "    \n",
        "    meta_df = pd.DataFrame(meta_train)\n",
        "    X_df['CATEGORY'] = meta_df['CATEGORY'].astype('category')\n",
        "    \n",
        "    y_arr = np.array(y_train_all)\n",
        "    \n",
        "    lgbm = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=20, n_jobs=-1)\n",
        "    model = MultiOutputRegressor(lgbm)\n",
        "    model.fit(X_df, y_arr)\n",
        "    \n",
        "    for category in cats_in_pulau:\n",
        "        sub_cat = df_subset[df_subset['PRODUCT_CATEGORY'] == category].sort_values('InvoiceDate')\n",
        "        last_series = sub_cat['Quantity'].values[-LOOK_BACK:]\n",
        "        last_series_log = np.log1p(last_series)\n",
        "        \n",
        "        feat_mean = np.mean(last_series_log)\n",
        "        feat_std = np.std(last_series_log)\n",
        "        \n",
        "        feat_payday = is_payday_week(future_dates[0])\n",
        "        \n",
        "        features = list(last_series_log) + [feat_mean, feat_std, feat_payday]\n",
        "        \n",
        "        input_row = pd.DataFrame([features], columns=feat_cols)\n",
        "        input_row['CATEGORY'] = category\n",
        "        input_row['CATEGORY'] = input_row['CATEGORY'].astype('category')\n",
        "        \n",
        "        pred_log = model.predict(input_row)[0]\n",
        "        pred_final = np.expm1(pred_log)\n",
        "        pred_final = np.maximum(pred_final, 0) \n",
        "        \n",
        "        for d, val in zip(future_dates, pred_final):\n",
        "            forecast_data_list.append({\n",
        "                'InvoiceDate': d,\n",
        "                'PULAU': p_name,\n",
        "                'PRODUCT_CATEGORY': category,\n",
        "                'Quantity': val,\n",
        "                'Data_Type': 'Forecast'\n",
        "            })\n",
        "\n",
        "print(\"Proses Selesai.\")\n",
        "\n",
        "df_history = pd.concat(history_data_list)\n",
        "df_forecast = pd.DataFrame(forecast_data_list)\n",
        "\n",
        "df_combined_pulau = pd.concat([df_history, df_forecast], axis=0).sort_values(['PULAU', 'PRODUCT_CATEGORY', 'InvoiceDate'])\n",
        "df_combined_pulau = df_combined_pulau.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nTotal Baris Data Gabungan: {len(df_combined_pulau)}\")\n",
        "print(\"Contoh Data:\")\n",
        "print(df_combined_pulau.tail())\n",
        "\n",
        "for p_name in unique_pulau:\n",
        "    subset_plot = df_combined_pulau[df_combined_pulau['PULAU'] == p_name]\n",
        "    categories = subset_plot['PRODUCT_CATEGORY'].unique()\n",
        "    \n",
        "    num_plots = len(categories)\n",
        "    cols = 10\n",
        "    rows = math.ceil(num_plots / cols)\n",
        "    \n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    fig.suptitle(f\"WILAYAH: {p_name}\\n(History + Future Forecast 10 Weeks)\", fontsize=20, fontweight='bold', y=1.005)\n",
        "    \n",
        "    for i, cat in enumerate(categories):\n",
        "        ax = axes[i]\n",
        "        \n",
        "        data_cat = subset_plot[subset_plot['PRODUCT_CATEGORY'] == cat]\n",
        "        \n",
        "        actual_data = data_cat[data_cat['Data_Type'] == 'Actual']\n",
        "        forecast_data = data_cat[data_cat['Data_Type'] == 'Forecast']\n",
        "        \n",
        "        if not actual_data.empty and not forecast_data.empty:\n",
        "            last_act = actual_data.iloc[-1]\n",
        "            connector = pd.DataFrame([last_act]).copy()\n",
        "            connector['Data_Type'] = 'Forecast_Connector' \n",
        "            forecast_plot = pd.concat([connector, forecast_data])\n",
        "        else:\n",
        "            forecast_plot = forecast_data\n",
        "        \n",
        "        start_plot = actual_data['InvoiceDate'].max() - pd.Timedelta(weeks=24)\n",
        "        actual_plot = actual_data[actual_data['InvoiceDate'] >= start_plot]\n",
        "        \n",
        "        ax.plot(actual_plot['InvoiceDate'], actual_plot['Quantity'], label='Actual', color='tab:blue', marker='o', markersize=4)\n",
        "        ax.plot(forecast_plot['InvoiceDate'], forecast_plot['Quantity'], label='Forecast', color='tab:red', linestyle='--', marker='x', markersize=4)\n",
        "        \n",
        "        ax.set_title(f\"{cat}\", fontsize=10, fontweight='bold')\n",
        "        ax.grid(alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
        "        \n",
        "        if i == 0: ax.legend(loc='upper left')\n",
        "        \n",
        "    for j in range(i+1, len(axes)): fig.delaxes(axes[j])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f262001f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_combined_pulau"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565e2d2b",
      "metadata": {},
      "source": [
        "## FP-Growth Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "babe288d",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Membersihkan Data...\")\n",
        "df_apriori['PRODUCT_CATEGORY'] = df_apriori['PRODUCT_CATEGORY'].astype(str).str.strip()\n",
        "\n",
        "df_apriori.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
        "df_apriori['InvoiceNo'] = df_apriori['InvoiceNo'].astype(str)\n",
        "df_apriori = df_apriori[df_apriori['Quantity'] > 0]\n",
        "\n",
        "print(f\"Total Transaksi Bersih: {len(df_apriori)}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "def analyze_basket_per_pulau(dataframe, pulau_name, min_sup=0.01, min_lift=1.0):\n",
        "    print(f\"\\nðŸ›’ Memproses Market Basket: {pulau_name}...\")\n",
        "    \n",
        "    df_subset = dataframe[dataframe['PULAU'] == pulau_name].copy()\n",
        "    \n",
        "    if df_subset.empty:\n",
        "        print(\"   -> Data kosong.\")\n",
        "        return None\n",
        "\n",
        "    item_counts = df_subset['PRODUCT_CATEGORY'].value_counts()\n",
        "    valid_items = item_counts[item_counts >= 5].index\n",
        "    df_subset = df_subset[df_subset['PRODUCT_CATEGORY'].isin(valid_items)]\n",
        "\n",
        "    basket = df_subset.pivot_table(index='InvoiceNo', columns='PRODUCT_CATEGORY', values='Quantity', aggfunc='sum').fillna(0)\n",
        "\n",
        "    basket_sets = basket.applymap(lambda x: True if x > 0 else False)\n",
        "    \n",
        "    if 'POSTAGE' in basket_sets.columns:\n",
        "        basket_sets.drop('POSTAGE', inplace=True, axis=1)\n",
        "\n",
        "    print(f\"   -> Dimensi Matrix: {basket_sets.shape}\")\n",
        "\n",
        "    try:\n",
        "        frequent_itemsets = fpgrowth(basket_sets, min_support=min_sup, use_colnames=True)\n",
        "    except MemoryError:\n",
        "        print(\"   âŒ Masih Memory Error. Coba naikkan min_support.\")\n",
        "        return None\n",
        "    \n",
        "    if frequent_itemsets.empty:\n",
        "        print(\"   -> Tidak ada itemset yang memenuhi support.\")\n",
        "        return None\n",
        "\n",
        "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
        "    \n",
        "    if rules.empty:\n",
        "        print(\"   -> Tidak ada rules yang memenuhi lift.\")\n",
        "        return None\n",
        "        \n",
        "    rules['PULAU'] = pulau_name\n",
        "    rules = rules.sort_values(['lift', 'confidence'], ascending=[False, False])\n",
        "    \n",
        "    return rules\n",
        "\n",
        "unique_pulau = df_apriori['PULAU'].unique()\n",
        "all_rules_list = []\n",
        "\n",
        "MIN_SUPPORT = 0.1\n",
        "MIN_LIFT = 2.0\n",
        "\n",
        "for pulau in unique_pulau:\n",
        "    rules_df = analyze_basket_per_pulau(df_apriori, pulau, min_sup=MIN_SUPPORT, min_lift=MIN_LIFT)\n",
        "    \n",
        "    if rules_df is not None:\n",
        "        all_rules_list.append(rules_df)\n",
        "        print(\"   -> Top 3 Rules:\")\n",
        "        print(rules_df[['antecedents', 'consequents', 'lift']].head(3).to_string(index=False))\n",
        "\n",
        "if all_rules_list:\n",
        "    final_mba_results = pd.concat(all_rules_list, ignore_index=True)\n",
        "    \n",
        "    final_mba_results['antecedents'] = final_mba_results['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
        "    final_mba_results['consequents'] = final_mba_results['consequents'].apply(lambda x: ', '.join(list(x)))\n",
        "    \n",
        "    print(\"\\nâœ… ANALISIS SELESAI!\")\n",
        "    print(f\"Total Rules: {len(final_mba_results)}\")\n",
        "    \n",
        "    print(\"\\n=== TOP 10 RULES TERKUAT (GLOBAL) ===\")\n",
        "    print(final_mba_results[['PULAU', 'antecedents', 'consequents', 'confidence', 'lift']].sort_values(by='lift', ascending=False).head(10))\n",
        "else:\n",
        "    print(\"\\nâŒ Tidak ada rules ditemukan. Coba turunkan min_support sedikit.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971d2ac6",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mba_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7aedd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mba_results['PULAU'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb5b34e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total Rules Sebelum Filter: {len(final_mba_results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5268b4b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "rules_viz = final_mba_results[\n",
        "    (final_mba_results['support'] >= 0.10) &\n",
        "    (final_mba_results['lift']    >= 2.0)\n",
        "].copy()\n",
        "\n",
        "rules_viz = rules_viz.sort_values(by='support', ascending=False).head(20)\n",
        "\n",
        "rules_viz['Rule_Label'] = rules_viz['antecedents'] + \" â†’ \" + rules_viz['consequents']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(\n",
        "    rules_viz['confidence'],\n",
        "    rules_viz['support'],\n",
        "    c=rules_viz['lift'],\n",
        "    s=rules_viz['lift'] * 80,   \n",
        "    cmap='plasma',\n",
        "    alpha=0.8,\n",
        "    edgecolor='k'\n",
        ")\n",
        "\n",
        "for _, row in rules_viz.head(10).iterrows():\n",
        "    plt.text(\n",
        "        row['confidence'],\n",
        "        row['support'],\n",
        "        row['Rule_Label'],\n",
        "        fontsize=8,\n",
        "        ha='left',\n",
        "        va='bottom'\n",
        "    )\n",
        "\n",
        "plt.colorbar(scatter, label='Lift')\n",
        "plt.title('Top Frequent Itemsets (min_support â‰¥ 0.10, lift > 2.0)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Confidence')\n",
        "plt.ylabel('Support')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
